{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import wandb\n",
    "import datetime\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import copy\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "from models.model_cae import model_cae\n",
    "from models.sw_cls_cae_pretrained import sw_cls_cae_pretrained\n",
    "from utility_functions.awe_dataset_class import awe_dataset_pre_computed_pre_training\n",
    "from utility_functions.utils_function import (average_precision, collate_fn_pre_training)\n",
    "import torch.nn.functional as F\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff1947c0cd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(3112)\n",
    "torch.cuda.manual_seed(3112)\n",
    "torch.cuda.manual_seed_all(3112)\n",
    "np.random.seed(3112)\n",
    "random.seed(3112)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(3121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirectional=True\n",
    "batch_size=1\n",
    "metadata_file=\"../data/hubert_features/hubert_feature_metadata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is device CUDA: False\n",
      "number of workers: 0\n",
      "pin memory status: False\n"
     ]
    }
   ],
   "source": [
    "print(\"Is device CUDA:\", device.type==\"cuda\")\n",
    "if device.type == \"cuda\":\n",
    "    num_workers = 4\n",
    "    pin_memory = True\n",
    "else:\n",
    "    num_workers = 0\n",
    "    pin_memory = False\n",
    "\n",
    "print(\"number of workers:\", num_workers)\n",
    "print(\"pin memory status:\", pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = awe_dataset_pre_computed_pre_training(\n",
    "    feature_df=metadata_file,\n",
    "    partition=\"train\")\n",
    "\n",
    "val_data = awe_dataset_pre_computed_pre_training(\n",
    "    feature_df=metadata_file,\n",
    "    partition=\"val\"\n",
    ")\n",
    "test_data = awe_dataset_pre_computed_pre_training(\n",
    "    feature_df=metadata_file,\n",
    "    partition=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(range(len(train_data)), 1000, replace=False)\n",
    "train_data = torch.utils.data.Subset(train_data, indices)\n",
    "indices = np.random.choice(range(len(val_data)), 1000, replace=False)\n",
    "val_data = torch.utils.data.Subset(val_data, indices)\n",
    "test_data = torch.utils.data.Subset(test_data, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of training data: 1000\n",
      "length of validation data: 1000\n",
      "length of test data: 1000\n"
     ]
    }
   ],
   "source": [
    "print(\"length of training data:\",len(train_data))\n",
    "print(\"length of validation data:\",len(val_data))\n",
    "print(\"length of test data:\",len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn_pre_training,\n",
    "    drop_last = False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn_pre_training,\n",
    "    drop_last = False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn_pre_training,\n",
    "    drop_last = False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim=768\n",
    "hidden_dim=256\n",
    "embedding_dim=128\n",
    "rnn_type=\"GRU\"\n",
    "num_layers=4\n",
    "dropout=0.2\n",
    "model_weights1=\"../checkpoints/model_hubert/hubert_01/HUBERT_BASE_128_BEST.pt\"\n",
    "model_weights2=\"../checkpoints/model_subword_classification/sub_classification_01/HUBERT_BASE_128_BEST.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../checkpoints/model_subword_classification/sub_classification_01/dict_tokens.pt'\n",
    "\n",
    "dict_tokens = torch.load(filename)\n",
    "classes = dict_tokens.keys()\n",
    "idx_to_class = {i:j for i, j in enumerate(classes)}\n",
    "class_to_idx = {value:key for key,value in idx_to_class.items()}\n",
    "num_classes = len(dict_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sw_cls_cae_pretrained(\n",
      "  (encoder): Encoder(\n",
      "    (rnn_enc): GRU(768, 256, num_layers=4, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "    (fc_enc): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (tanh): Tanh()\n",
      "  )\n",
      "  (attention): Attention(\n",
      "    (attn): Linear(in_features=640, out_features=128, bias=True)\n",
      "    (v): Linear(in_features=128, out_features=1, bias=False)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (attention): Attention(\n",
      "      (attn): Linear(in_features=640, out_features=128, bias=True)\n",
      "      (v): Linear(in_features=128, out_features=1, bias=False)\n",
      "    )\n",
      "    (embedding): Embedding(188, 128)\n",
      "    (rnn): GRU(640, 128)\n",
      "    (fc_out): Linear(in_features=768, out_features=188, bias=True)\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## Define the pre-trained model\n",
    "pre_model = model_cae(input_dim, hidden_dim, embedding_dim, \n",
    "                        rnn_type, bidirectional, num_layers, \n",
    "                        dropout)\n",
    "# # print(pre_model)\n",
    "# pre_model_checkpoint = torch.load(model_weights1, \n",
    "#                                   map_location=torch.device(device))\n",
    "# # print(pre_model_checkpoint['model_state_dict'])\n",
    "# pre_model.load_state_dict(pre_model_checkpoint['model_state_dict'])\n",
    "# pre_model.eval()\n",
    "\n",
    "# pre_model = pre_model.to(device)\n",
    "# for param in pre_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "## Define the model\n",
    "\n",
    "model = sw_cls_cae_pretrained(hidden_dim, embedding_dim, rnn_type, \n",
    "                  bidirectional, num_layers, num_classes, dropout, \n",
    "                  pre_model.encoder)\n",
    "model_checkpoint = torch.load(model_weights2, \n",
    "                                  map_location=torch.device(device))\n",
    "model.load_state_dict(model_checkpoint['model_state_dict'])\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(model.parameters())\n",
    "# check gradient is False or not\n",
    "# for param in params:\n",
    "#     print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 5736252\n"
     ]
    }
   ],
   "source": [
    "cumu = 0\n",
    "for layer in params:\n",
    "    cumu += layer.numel()\n",
    "\n",
    "print(\"Total number of parameters:\", cumu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doop(l):\n",
    "  return ''.join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(model, data_loader, device, max_length=12):\n",
    "    model.eval()\n",
    "    EOW_token = 1\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    attention_list = []\n",
    "    for idx, (data,lens,word_name,_,token,token_len) in enumerate(data_loader):\n",
    "        # print(idx)\n",
    "        # for m in range(len(token)):\n",
    "        #     for subword in range(len(token[m])):\n",
    "        #         token[m][subword] = class_to_idx[token[m][subword]]\n",
    "        #     token[m] = torch.tensor(token[m])\n",
    "        # token = torch.utils.pad_sequence(token, batch_first=True, padding_value=class_to_idx['PAD'])\n",
    "        token = torch.from_numpy(np.vectorize(class_to_idx.get)(token))\n",
    "        data, lens, token = data.to(device), lens.to(device), token.to(device)\n",
    "        if  device.type == 'cuda()':\n",
    "            # print(\"cuda\")\n",
    "            word_name = word_name.cpu()\n",
    "        # else:\n",
    "        #     # print(\"cpu\")\n",
    "        with torch.no_grad():\n",
    "            encoder_outputs, encoded_x = model.encoder(data, lens)\n",
    "            # encoded_x = model.scale_encoder(encoded_x)\n",
    "\n",
    "        decoded_subwords = []\n",
    "        # decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        # batch_size = token.size(0)\n",
    "        trg = token.T # [token len, batch size]\n",
    "        # trg_len = trg.size(0) # [token_len]\n",
    "        input = trg[0,:] # [batch_size,1,1]\n",
    "        hidden = encoded_x # [1, batch_size,embedding_dim/hidden dim]\n",
    "        mask = model.create_mask(data)\n",
    "        attentions = torch.zeros(max_length, 1, lens).to(device)\n",
    "        for di in range(1,max_length):\n",
    "            output, hidden, attention = model.decoder(\n",
    "                input, hidden, encoder_outputs, mask)\n",
    "            attentions[di] = attention\n",
    "            top1 = output.argmax(1)\n",
    "            if top1.item()==EOW_token:\n",
    "                # print(\"detected end of word token\")\n",
    "                decoded_subwords.append([idx_to_class[index.item()].replace(\"▁\",\"\").replace(\"EOW\",\"\").upper() for index in top1])\n",
    "                break\n",
    "            else:\n",
    "                decoded_subwords.append([idx_to_class[index.item()].replace(\"▁\",\"\").replace(\"EOW\",\"\").upper() for index in top1])\n",
    "            input = top1.detach()\n",
    "        decoded_words = np.apply_along_axis(doop, 0, np.array(decoded_subwords))\n",
    "        # print(di, decoded_words)\n",
    "        y_true = y_true + list(word_name)\n",
    "        y_pred = y_pred + decoded_words.tolist()\n",
    "        # attention_list = attention_list.append(attention)\n",
    "        # if idx%1==0:\n",
    "        #     print(idx)\n",
    "        #     return y_true, y_pred, attentions\n",
    "        #     break\n",
    "\n",
    "    accuracy = accuracy_score(y_true,y_pred)\n",
    "    print(\"accuracy\", accuracy)\n",
    "\n",
    "    return accuracy,attention_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.996\n",
      "train_accuracy (0.996, [])\n",
      "accuracy 0.883\n",
      "val_accuracy (0.883, [])\n",
      "accuracy 0.889\n",
      "test_accuracy (0.889, [])\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = evaluate_accuracy(model, train_loader, device)\n",
    "print(\"train_accuracy\", train_accuracy)\n",
    "val_accuracy = evaluate_accuracy(model, val_loader, device)\n",
    "print(\"val_accuracy\", val_accuracy)\n",
    "test_accuracy = evaluate_accuracy(model, test_loader, device)\n",
    "print(\"test_accuracy\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate2(model, data, lens, word_name, token, device, max_length=12):\n",
    "#     model.eval()\n",
    "#     EOW_token = 1\n",
    "#     token = torch.from_numpy(np.vectorize(class_to_idx.get)(token))\n",
    "#     data, lens, token = data.to(device), lens.to(device), token.to(device)\n",
    "#     word_name = word_name ## .cpu()\n",
    "#     with torch.no_grad():\n",
    "#         encoder_outputs, encoded_x = model.encoder(data, lens)\n",
    "#         encoded_x = model.scale_encoder(encoded_x)\n",
    "\n",
    "#     decoded_subwords = []\n",
    "#     trg = token.T # [token len, batch size]\n",
    "#     # trg_len = trg.size(0) # [token_len]\n",
    "#     input = trg[0,:] # [batch_size,1,1]\n",
    "#     hidden = encoded_x # [1, batch_size,embedding_dim/hidden dim]\n",
    "#     mask = model.create_mask(data)\n",
    "#     attentions = torch.zeros(max_length, 1, lens).to(device)\n",
    "#     for di in range(1,max_length):\n",
    "#         output, hidden, attention,_ = model.decoderV(\n",
    "#             input, hidden, encoder_outputs, mask,torch.tensor([di-1]))\n",
    "#         attentions[di] = attention\n",
    "#         top1 = output.argmax(1)\n",
    "#         if top1.item()==EOW_token:\n",
    "#             # print(\"detected end of word token\")\n",
    "#             decoded_subwords.append([idx_to_class[index.item()] for index in top1])\n",
    "#             break\n",
    "#         else:\n",
    "#             decoded_subwords.append([idx_to_class[index.item()] for index in top1])\n",
    "#         input = top1.detach()\n",
    "        \n",
    "#     return decoded_subwords, attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_attn(model, data, lens, word_name, token, device, max_length=11):\n",
    "    model.eval()\n",
    "    EOW_token = 1\n",
    "    SOW_token = 0\n",
    "    token = torch.from_numpy(np.vectorize(class_to_idx.get)(token))\n",
    "    data, lens, token = data.to(device), lens.to(device), token.to(device)\n",
    "    # print(len(token))\n",
    "    if  device.type == 'cuda()':\n",
    "        # print(\"cuda\")\n",
    "        word_name = word_name.cpu()\n",
    "    # else:\n",
    "    #     print(\"cpu\")\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, encoded_x = model.encoder(data, lens)\n",
    "        # encoded_x = model.scale_encoder(encoded_x)\n",
    "    mask = model.create_mask(data)\n",
    "    trg_indexes = [SOW_token]\n",
    "\n",
    "\n",
    "    hidden = encoded_x # [1, batch_size,embedding_dim/hidden dim]\n",
    "    \n",
    "    attentions = torch.zeros(max_length, 1, lens).to(device)\n",
    "\n",
    "    for di in range(max_length):\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "        output, hidden, attention = model.decoder(\n",
    "            trg_tensor, hidden, encoder_outputs, mask)\n",
    "        attentions[di] = attention\n",
    "        pred_token = output.argmax(1).item()\n",
    "        trg_indexes.append(pred_token)\n",
    "        if pred_token == EOW_token:\n",
    "            break\n",
    "\n",
    "    trg_tokens = [idx_to_class[i] for i in trg_indexes]\n",
    "        \n",
    "    return trg_tokens[1:], attentions[:len(trg_tokens)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (data,lens,word_name,_,token,token_len) in enumerate(val_loader):\n",
    "    a,b = evaluate_attn(model, data, lens, word_name, token, device)\n",
    "    if idx==0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'ther', 'ther', 's', 'EOW'] torch.Size([5, 1, 35]) ['OTHERS']\n"
     ]
    }
   ],
   "source": [
    "print(a,b.shape,word_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_attention(sentence, translation, attention):\n",
    "    \n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
    "    \n",
    "    cax = ax.matshow(attention, cmap='bone')\n",
    "   \n",
    "    ax.tick_params(labelsize=15)\n",
    "    \n",
    "    x_ticks = [''] + ['<sow>'] + [t.lower() for t in sentence] + ['<eow>']\n",
    "    y_ticks = [''] + translation\n",
    "     \n",
    "    ax.set_xticklabels(x_ticks, rotation=45)\n",
    "    ax.set_yticklabels(y_ticks)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21070/882002334.py:15: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels(x_ticks, rotation=45)\n",
      "/tmp/ipykernel_21070/882002334.py:16: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels(y_ticks)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence = [\"x_\" + str(i) for i in range(b.shape[2])]\n",
    "display_attention(sentence,a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_sub_emb = {p : [] for p in range(10)}\n",
    "# dict_sub_emb_id = {p : [] for p in range(10)}\n",
    "# for idx, (data,lens,word_name,_,token,token_len) in enumerate(test_loader):\n",
    "#     trg_tokens,_,sub_emb = evaluate_attn(model, data, lens, word_name, token, device)\n",
    "#     # token = token[0][1:-1] # remove start and end of word token\n",
    "#     # note: can't use token because it is not the same as the token predicted by the model, which is trg_tokens, can have differnt length\n",
    "#     for i in range(len(trg_tokens)-1):    # -1 because we don't want to include the end of word token as a subword\n",
    "#         dict_sub_emb[i].append(sub_emb[i].detach())\n",
    "#         dict_sub_emb_id[i].append(class_to_idx[trg_tokens[i]])\n",
    "#     if idx==5000:\n",
    "#         print(idx)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marlanx marlanx same\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "dict_sub_emb = {p : [] for p in range(10)}\n",
    "dict_sub_emb_id = {p : [] for p in range(10)}\n",
    "count = 0\n",
    "for idx, (data,lens,word_name,_,token,token_len) in enumerate(test_loader):\n",
    "    trg_tokens,_,sub_emb = evaluate_attn(model, data, lens, word_name, token, device)\n",
    "    trg_tokens = trg_tokens[:-1] # -1 because we don't want to include the end of word token as a subword\n",
    "    token = token[0][1:-1] # 1, -1 because we don't want to include the start and end of word token as a subword\n",
    "    if ''.join(trg_tokens) != ''.join(token):\n",
    "        print(''.join(trg_tokens), ''.join(token), 'different')\n",
    "        count += 1\n",
    "    else:   \n",
    "        print(''.join(trg_tokens), ''.join(token), 'same')\n",
    "        for i in range(len(trg_tokens)):    \n",
    "            dict_sub_emb[i].append(sub_emb[i].detach())\n",
    "            dict_sub_emb_id[i].append(class_to_idx[trg_tokens[i]])\n",
    "        if idx%100==0:\n",
    "            print(idx)\n",
    "            break\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oswald'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(trg_tokens[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oswald'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(token[0][1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dict_sub_emb[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dict_sub_emb_id[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = torch.cat(dict_sub_emb[1],0).to(torch.float16).numpy()\n",
    "ids = np.array(dict_sub_emb_id[1])\n",
    "avg_precision,_ = average_precision(embs, ids, \"cosine\", show_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = torch.cat(dict_sub_emb[10],0).to(torch.float16).numpy()\n",
    "ids = np.array(dict_sub_emb_id[10])\n",
    "avg_precision,_ = average_precision(embs, ids, \"cosine\", show_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_avg_precision = []\n",
    "for i in range(len(dict_sub_emb)):\n",
    "    embs = torch.cat(dict_sub_emb[i],0).to(torch.float16).numpy()\n",
    "    ids = np.array(dict_sub_emb_id[i])\n",
    "    avg_precision,_ = average_precision(embs, ids, \"cosine\", show_plot=False)\n",
    "    test_avg_precision.append(avg_precision)\n",
    "    print(\"average precision for subword at position {} is {}\".format(i,avg_precision))\n",
    "\n",
    "print(\"average precision for all subwords is {}\".format(np.mean(test_avg_precision)))\n",
    "\n",
    "\n",
    "\n",
    "# sub_embeddings, ids = torch.cat(dict_sub_emb[0],0).to(torch.float16).numpy(), np.array(dict_sub_emb_id[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "# # create dictoinary of dictionary with position as key and value as list of subword embeddings\n",
    "# dict_pos = {p : {} for p in range(10)}\n",
    "# dict_pos_count = {p : {} for p in range(10)}\n",
    "# for idx, (data,lens,word_name,_,token,token_len) in enumerate(train_loader):\n",
    "#     a,b,c = evaluate_attn(model, data, lens, word_name, token, device)\n",
    "#     a = a[:-1] # remove <eow> token\n",
    "#     token = token[0][1:] # remove <sow> token\n",
    "#     for i in range(len(a)):\n",
    "#         if a[i] not in dict_pos[i]:\n",
    "#             dict_pos[i][a[i]] = c[i]\n",
    "#             dict_pos_count[i][a[i]] = 1\n",
    "#         else:\n",
    "#             dict_pos[i][a[i]] += c[i]\n",
    "#             dict_pos_count[i][a[i]] += 1\n",
    "#     if idx==1000:        \n",
    "#         print(idx)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "telegraph telegraph same\n",
      "accusations accusations same\n",
      "proportionately proportionately same\n",
      "perfect perfect same\n",
      "acknowledging acknowledging same\n",
      "starfish starfish same\n",
      "seldom seldom same\n",
      "grandfather grandfather same\n",
      "apopologize apologize different\n",
      "combatants combatants same\n",
      "seclusion seclusion same\n",
      "foretold foretold same\n",
      "intermediate intermediate same\n",
      "solicited solicited same\n",
      "talker talker same\n",
      "archipelago archipelago same\n",
      "incompparable incomparable different\n",
      "terriers terriers same\n",
      "contradictcted contradicted different\n",
      "correspondent correspondent same\n",
      "thorns thorns same\n",
      "foot foot same\n",
      "crude crude same\n",
      "currants currants same\n",
      "honestly honestly same\n",
      "tarzan tarzan same\n",
      "perverse perverse same\n",
      "favourite favourite same\n",
      "fairies fairies same\n",
      "needful needful same\n",
      "objective objective same\n",
      "rather rather same\n",
      "enveloped enveloped same\n",
      "worthiness worthiness same\n",
      "delegates delegates same\n",
      "fraser fraser same\n",
      "scaffold scaffold same\n",
      "concentrate concentrate same\n",
      "symbol symbol same\n",
      "unconciousousnessous unconsciousness different\n",
      "califormia california different\n",
      "dispersed dispersed same\n",
      "bickerssdyke bickersdyke different\n",
      "tumultuous tumultuous same\n",
      "womanhood womanhood same\n",
      "remind remind same\n",
      "smelling smelling same\n",
      "gymnasium gymnasium same\n",
      "cavalcanti cavalcanti same\n",
      "achieve achieve same\n",
      "lighthouse lighthouse same\n",
      "philammon philammon same\n",
      "achieve achieve same\n",
      "awoke awoke same\n",
      "abolition abolition same\n",
      "utterly utterly same\n",
      "postscript postscript same\n",
      "intrigue intrigue same\n",
      "caught caught same\n",
      "instantentaneouslyly instantaneously different\n",
      "tormented tormented same\n",
      "torch torch same\n",
      "subscription subscription same\n",
      "modestly modestly same\n",
      "played played same\n",
      "pamphlet pamphlet same\n",
      "vigilance vigilance same\n",
      "oxford oxford same\n",
      "melbourne melbourne same\n",
      "concsessions concessions different\n",
      "hills hills same\n",
      "stratagem stratagem same\n",
      "operated operated same\n",
      "creditors creditors same\n",
      "eighteen eighteen same\n",
      "carlisle carlisle same\n",
      "steeds steeds same\n",
      "extremities extremities same\n",
      "illness illness same\n",
      "sawdust sawdust same\n",
      "antoinette antoinette same\n",
      "syracusansens syracusans different\n",
      "theseus theseus same\n",
      "expositionion exposition different\n",
      "protestant protestant same\n",
      "insurgents insurgents same\n",
      "acclamationsations acclamations different\n",
      "conformity conformity same\n",
      "umbrellas umbrellas same\n",
      "goods goods same\n",
      "beggar beggar same\n",
      "roared roared same\n",
      "huskily huskily same\n",
      "seducedsed seduced different\n",
      "awkwardly awkwardly same\n",
      "appeared appeared same\n",
      "firelight firelight same\n",
      "cavern cavern same\n",
      "sweep sweep same\n",
      "dubious dubious same\n",
      "juliet juliet same\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# create dictoinary of dictionary with position as key and value as list of subword embeddings\n",
    "dict_pos = {p : {} for p in range(10)}\n",
    "dict_pos_count = {p : {} for p in range(10)}\n",
    "for idx, (data,lens,word_name,_,token,token_len) in enumerate(train_loader):\n",
    "    trg_tokens,b,c = evaluate_attn(model, data, lens, word_name, token, device)\n",
    "    trg_tokens = trg_tokens[:-1] # remove <eow> token\n",
    "    c = c[:-1] # remove <eow> token\n",
    "    token = token[0][1:-1] # remove <sow> token\n",
    "    if ''.join(trg_tokens) != ''.join(token):\n",
    "        print(''.join(trg_tokens), ''.join(token), 'different')\n",
    "    else:   \n",
    "        print(''.join(trg_tokens), ''.join(token), 'same')\n",
    "\n",
    "        for i in range(len(trg_tokens)):    \n",
    "            if trg_tokens[i] not in dict_pos[i]:\n",
    "                dict_pos[i][trg_tokens[i]] = c[i]\n",
    "                dict_pos_count[i][trg_tokens[i]] = 1\n",
    "            else:\n",
    "                dict_pos[i][trg_tokens[i]] += c[i]\n",
    "                dict_pos_count[i][trg_tokens[i]] += 1\n",
    "        if idx==100:        \n",
    "            print(idx)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['j', 'u', 'li', 'et']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 128])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['to', 'r', 't', 'u', 'res', 'EOW'], dtype=object)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to', 'r', 't', 'u', 'res', 'EOW']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the averratge of all the subword embeddings base on the position dictionary count\n",
    "for i in range(len(dict_pos)):\n",
    "    for key in dict_pos[i]:\n",
    "        dict_pos[i][key] = F.normalize(dict_pos[i][key]/dict_pos_count[i][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.norm(dict_pos[5]['EOW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the list of words in the test set that are not in the train set\n",
    "## after that, generate and cacluate AP-CW\n",
    "# test_words = []\n",
    "# for idx, (data,lens,word_name,_,token,token_len) in enumerate(test_loader):\n",
    "#     test_words.extend(word_name)\n",
    "\n",
    "df_train = pd.read_csv(\"../e2e_subword_embedding_1/data_final_7000/train.csv\")\n",
    "df_test = pd.read_csv(\"../e2e_subword_embedding_1/data_final_7000/test.csv\")\n",
    "df_val = pd.read_csv(\"../e2e_subword_embedding_1/data_final_7000/val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename= \"dict_pos.pt\"\n",
    "if os.path.exists(filename):\n",
    "    dict_pos = torch.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>flag</th>\n",
       "      <th>start</th>\n",
       "      <th>duration</th>\n",
       "      <th>word</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>count_tokens</th>\n",
       "      <th>sp_id_and_ch_id</th>\n",
       "      <th>filename_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSP-140711-0008_1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.46</td>\n",
       "      <td>0.66</td>\n",
       "      <td>JERVIS</td>\n",
       "      <td>['j', 'er', 'v', 'is']</td>\n",
       "      <td>4</td>\n",
       "      <td>-140711-0008</td>\n",
       "      <td>./train-other-500/3587/140711/3587-140711-0008...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSP-132570-0000_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.64</td>\n",
       "      <td>DISPUTING</td>\n",
       "      <td>['d', 'is', 'p', 'ut', 'ing']</td>\n",
       "      <td>5</td>\n",
       "      <td>-132570-0000</td>\n",
       "      <td>./train-clean-100/2007/132570/2007-132570-0000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSP-5059-0002_1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>SATISFACTORILY</td>\n",
       "      <td>['s', 'at', 'is', 'f', 'ac', 'to', 'ri', 'ly']</td>\n",
       "      <td>8</td>\n",
       "      <td>-5059-0002</td>\n",
       "      <td>./train-other-500/2930/5059/2930-5059-0002.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSP-172162-0032_1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.33</td>\n",
       "      <td>0.81</td>\n",
       "      <td>UNOCCUPIED</td>\n",
       "      <td>['u', 'no', 'c', 'c', 'up', 'i', 'ed']</td>\n",
       "      <td>7</td>\n",
       "      <td>-172162-0032</td>\n",
       "      <td>./train-clean-100/3436/172162/3436-172162-0032...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSP-287660-0003_1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.25</td>\n",
       "      <td>0.56</td>\n",
       "      <td>TESTIFIED</td>\n",
       "      <td>['t', 'est', 'if', 'i', 'ed']</td>\n",
       "      <td>5</td>\n",
       "      <td>-287660-0003</td>\n",
       "      <td>./train-clean-360/8506/287660/8506-287660-0003...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  flag  start  duration            word  \\\n",
       "0  LSP-140711-0008_1     1   5.46      0.66          JERVIS   \n",
       "1  LSP-132570-0000_1     1   1.59      0.64       DISPUTING   \n",
       "2    LSP-5059-0002_1     1   3.96      0.94  SATISFACTORILY   \n",
       "3  LSP-172162-0032_1     1   5.33      0.81      UNOCCUPIED   \n",
       "4  LSP-287660-0003_1     1   8.25      0.56       TESTIFIED   \n",
       "\n",
       "                                        tokenized  count_tokens  \\\n",
       "0                          ['j', 'er', 'v', 'is']             4   \n",
       "1                   ['d', 'is', 'p', 'ut', 'ing']             5   \n",
       "2  ['s', 'at', 'is', 'f', 'ac', 'to', 'ri', 'ly']             8   \n",
       "3          ['u', 'no', 'c', 'c', 'up', 'i', 'ed']             7   \n",
       "4                   ['t', 'est', 'if', 'i', 'ed']             5   \n",
       "\n",
       "  sp_id_and_ch_id                                      filename_path  \n",
       "0    -140711-0008  ./train-other-500/3587/140711/3587-140711-0008...  \n",
       "1    -132570-0000  ./train-clean-100/2007/132570/2007-132570-0000...  \n",
       "2      -5059-0002    ./train-other-500/2930/5059/2930-5059-0002.flac  \n",
       "3    -172162-0032  ./train-clean-100/3436/172162/3436-172162-0032...  \n",
       "4    -287660-0003  ./train-clean-360/8506/287660/8506-287660-0003...  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6799\n"
     ]
    }
   ],
   "source": [
    "unique_word_train = df_train['word'].unique()\n",
    "print(len(unique_word_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5364\n"
     ]
    }
   ],
   "source": [
    "unique_word_test = df_test['word'].unique()\n",
    "print(len(unique_word_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_train = set(unique_word_train)\n",
    "set_test = set(unique_word_test)\n",
    "not_common = set_test - set_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(not_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "tokenizer = Tokenizer.from_file(\"../tokenizer-bpe200.json\")\n",
    "df_test_emb = torch.load(\"../paper2/embeddings_final/test_emb_norm.pt\")\n",
    "df_test = pd.read_csv(\"../paper2/embeddings_final/test_emb.csv\", converters={'tokenized': literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0754,  0.0947, -0.1163,  ...,  0.1009,  0.1055,  0.0906],\n",
       "        [ 0.1224,  0.0887, -0.1109,  ..., -0.0439,  0.0095, -0.0928],\n",
       "        [ 0.1198,  0.0781, -0.1141,  ..., -0.0280,  0.0867,  0.0907],\n",
       "        ...,\n",
       "        [ 0.1077,  0.0913, -0.1331,  ...,  0.0783, -0.1260, -0.1049],\n",
       "        [ 0.1180, -0.0548, -0.1337,  ..., -0.0490, -0.1388,  0.0196],\n",
       "        [-0.0450,  0.1079, -0.1352,  ...,  0.0050, -0.0254, -0.0924]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5031, 3105, 5028, ..., 4664, 1815, 2215])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['ids'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average precision on test set - AP-SD : 0.9577458207536054\n"
     ]
    }
   ],
   "source": [
    "sub_embeddings = df_test_emb\n",
    "ids = df_test['ids'].values\n",
    "test_avg_precision,_ = average_precision(sub_embeddings.cpu(),ids, \"cosine\",show_plot=False)\n",
    "print(\"average precision on test set words - AP :\", test_avg_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_test[df_test['count_tokens']==11]['word'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>words</th>\n",
       "      <th>ids</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1182-134981-0042</td>\n",
       "      <td>UNCONTROLLABLE</td>\n",
       "      <td>5031</td>\n",
       "      <td>[un, con, t, ro, ll, ab, le]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>296-142727-0013</td>\n",
       "      <td>MOSQUITOES</td>\n",
       "      <td>3105</td>\n",
       "      <td>[mo, s, qu, i, to, es]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1740-141148-0078</td>\n",
       "      <td>UNCOMPROMISING</td>\n",
       "      <td>5028</td>\n",
       "      <td>[un, com, p, rom, is, ing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1695-142312-0079</td>\n",
       "      <td>CONSISTENCY</td>\n",
       "      <td>982</td>\n",
       "      <td>[con, s, is, t, en, c, y]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8799-270794-0014</td>\n",
       "      <td>INDIRECTLY</td>\n",
       "      <td>2468</td>\n",
       "      <td>[ind, i, re, ct, ly]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          unique_id           words   ids                     tokenized\n",
       "0  1182-134981-0042  UNCONTROLLABLE  5031  [un, con, t, ro, ll, ab, le]\n",
       "1   296-142727-0013      MOSQUITOES  3105        [mo, s, qu, i, to, es]\n",
       "2  1740-141148-0078  UNCOMPROMISING  5028    [un, com, p, rom, is, ing]\n",
       "3  1695-142312-0079     CONSISTENCY   982     [con, s, is, t, en, c, y]\n",
       "4  8799-270794-0014      INDIRECTLY  2468          [ind, i, re, ct, ly]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14090"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test['tokenized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>words</th>\n",
       "      <th>ids</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4345-7635-0040</td>\n",
       "      <td>HOUNDS</td>\n",
       "      <td>2329</td>\n",
       "      <td>[h, ound, s]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4396-14564-0020</td>\n",
       "      <td>TILES</td>\n",
       "      <td>4887</td>\n",
       "      <td>[t, il, es]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2380-152158-0076</td>\n",
       "      <td>INHERENT</td>\n",
       "      <td>2518</td>\n",
       "      <td>[in, her, ent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1924-132576-0011</td>\n",
       "      <td>HOLLAND</td>\n",
       "      <td>2288</td>\n",
       "      <td>[ho, ll, and]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>7011-66622-0040</td>\n",
       "      <td>BEANS</td>\n",
       "      <td>411</td>\n",
       "      <td>[be, an, s]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14069</th>\n",
       "      <td>441-128982-0030</td>\n",
       "      <td>REMOVE</td>\n",
       "      <td>4014</td>\n",
       "      <td>[re, mo, ve]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14070</th>\n",
       "      <td>1746-143015-0024</td>\n",
       "      <td>BORNE</td>\n",
       "      <td>548</td>\n",
       "      <td>[b, or, ne]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14074</th>\n",
       "      <td>7285-72200-0018</td>\n",
       "      <td>JAIL</td>\n",
       "      <td>2621</td>\n",
       "      <td>[j, a, il]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14079</th>\n",
       "      <td>2751-142363-0039</td>\n",
       "      <td>FOGG</td>\n",
       "      <td>1857</td>\n",
       "      <td>[fo, g, g]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14085</th>\n",
       "      <td>3221-138045-0050</td>\n",
       "      <td>FOLLY</td>\n",
       "      <td>1866</td>\n",
       "      <td>[fo, l, ly]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2071 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              unique_id     words   ids       tokenized\n",
       "6        4345-7635-0040    HOUNDS  2329    [h, ound, s]\n",
       "23      4396-14564-0020     TILES  4887     [t, il, es]\n",
       "30     2380-152158-0076  INHERENT  2518  [in, her, ent]\n",
       "57     1924-132576-0011   HOLLAND  2288   [ho, ll, and]\n",
       "59      7011-66622-0040     BEANS   411     [be, an, s]\n",
       "...                 ...       ...   ...             ...\n",
       "14069   441-128982-0030    REMOVE  4014    [re, mo, ve]\n",
       "14070  1746-143015-0024     BORNE   548     [b, or, ne]\n",
       "14074   7285-72200-0018      JAIL  2621      [j, a, il]\n",
       "14079  2751-142363-0039      FOGG  1857      [fo, g, g]\n",
       "14085  3221-138045-0050     FOLLY  1866     [fo, l, ly]\n",
       "\n",
       "[2071 rows x 4 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['tokenized'].str.len()==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique words in test set 5364\n",
      "not found rom\n",
      "not found ard\n",
      "not found x\n",
      "not found to\n",
      "not found ke\n",
      "not found it\n",
      "not found if\n",
      "not found ard\n",
      "not found ast\n",
      "not found ing\n",
      "not found ri\n",
      "not found d\n",
      "not found ur\n",
      "not found lo\n",
      "not found j\n",
      "not found [UNK]\n",
      "not found it\n",
      "not found ast\n",
      "not found b\n",
      "not found ac\n",
      "not found up\n",
      "total unique words in test set 5343\n",
      "Average precision for reconstructed words (AP-CW): 0.0009852214374123417\n"
     ]
    }
   ],
   "source": [
    "shuffle_pos = \"no\"\n",
    "# unique_words = df_test[df_test['tokenized'].str.len()==3]['words'].unique()\n",
    "unique_words = df_test['words'].unique()\n",
    "print(\"total unique words in test set\",len(unique_words))\n",
    "\n",
    "artificial_words = np.zeros(shape=(len(unique_words),128)) ## embedding dim is input_dim  here\n",
    "\n",
    "if shuffle_pos ==\"no\":\n",
    "    flag = [True]*len(unique_words)\n",
    "    for i, w in enumerate(unique_words):\n",
    "        bpe_list = tokenizer.encode(w.lower()).tokens\n",
    "        sum_emb = torch.zeros(1,128)\n",
    "        for j in range(len(bpe_list)):\n",
    "            if bpe_list[j] in dict_pos[j]:\n",
    "                sum_emb += dict_pos[j][bpe_list[j]].detach()\n",
    "            else:\n",
    "                flag[i] = False\n",
    "                print(\"not found\",bpe_list[j])\n",
    "                break\n",
    "        artificial_words[i] = torch.tanh(model.proj_layer(sum_emb)).detach().numpy()\n",
    "    artificial_words = F.normalize(torch.from_numpy(artificial_words)).numpy()\n",
    "    artificial_words = artificial_words[flag]\n",
    "    unique_words = unique_words[flag]\n",
    "    print(\"total unique words in test set\",len(unique_words))\n",
    "    lista = unique_words\n",
    "    listb = df_test[\"words\"].values\n",
    "\n",
    "    labels = []\n",
    "    for i in lista:\n",
    "        for j in listb:\n",
    "            if i==j:\n",
    "                labels.append(True)\n",
    "            else:\n",
    "                labels.append(False)\n",
    "    ap_rw, _ = metric2(artificial_words, df_test_emb, np.array(labels), \"cosine\") ## calculate df_test_emb befoer hand\n",
    "\n",
    "    print(\"Average precision for reconstructed words (AP-CW):\", ap_rw)\n",
    "\n",
    "\n",
    "# else:\n",
    "#     flag = []\n",
    "#     for i, w in enumerate(unique_words):\n",
    "#         index = df_test_metadata[df_test_metadata[\"words\"] == w].index[0]\n",
    "#         bpe_list = df_test_metadata.iloc[index,3]\n",
    "\n",
    "#         if bpe_list[1] in list_sub_words3 and bpe_list[2] in list_sub_words2:\n",
    "#             sum_emb = sub_word_dict1[bpe_list[0]] + sub_word_dict3[bpe_list[1]] + sub_word_dict2[bpe_list[2]]\n",
    "#             flag.append(True)\n",
    "#         else: \n",
    "#             sum_emb = np.zeros((1,128))\n",
    "#             flag.append(False)\n",
    "\n",
    "#         if args.model_name==\"fact_net3\":\n",
    "#             sum_emb = torch.from_numpy(sum_emb)\n",
    "#             artificial_words[i] = torch.tanh(model.fc_projection(sum_emb.float())).detach().numpy()\n",
    "#         else:\n",
    "#             artificial_words[i] = sum_emb\n",
    "\n",
    "#     if args.norm==\"True\":\n",
    "#         artificial_words = F.normalize(torch.from_numpy(artificial_words)).numpy()\n",
    "\n",
    "#     artificial_words = artificial_words[flag]\n",
    "#     unique_words = unique_words[flag]\n",
    "\n",
    "#     lista = unique_words\n",
    "#     listb = df_test_metadata[\"words\"].values\n",
    "\n",
    "#     labels = []\n",
    "#     for i in lista:\n",
    "#         for j in listb:\n",
    "#             if i==j:\n",
    "#                 labels.append(True)\n",
    "#             else:\n",
    "#                 labels.append(False)\n",
    "#     test_metric2, _ = metric2(artificial_words, df_test_emb, np.array(labels), args.distance)\n",
    "\n",
    "    # print(\"Average precision for reconstructed words (AP-RW) for swapped pos 2 and 3:\", test_metric2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, dtype=torch.float64)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(torch.tensor(artificial_words[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f806f066ad0>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(model.decoderV.pos_embedding.weight.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(dict_pos[0]['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['UNCONTROLLABLE', 'MOSQUITOES', 'UNCOMPROMISING', ..., 'BRUSH',\n",
       "       'COLOR', 'FOLLY'], dtype=object)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14090, 128])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14064"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75466040"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = torch.tensor([7,3,4,5])\n",
    "mask = torch.repeat_interleave(torch.ones(4,768), lens, dim=0, output_size=sum(lens))\n",
    "mask = torch.split(mask, lens.tolist())\n",
    "mask_padded = torch.nn.utils.rnn.pad_sequence(mask, batch_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 4, 768])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_padded[3,1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_awe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
